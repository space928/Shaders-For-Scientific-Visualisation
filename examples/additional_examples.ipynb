{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3493ef7e-eed2-410b-b3a2-64f3a165f0b1",
   "metadata": {},
   "source": [
    "# Additional Examples\n",
    "This notebook contains more advanced examples using pySSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53a5b8c-76f5-4f15-892b-87c4ed1fa4cd",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# Google colab support\n",
    "try:\n",
    "    # Try enabling custom widgets, this will fail silently if we're not in Google Colab\n",
    "    from google.colab import output\n",
    "    output.enable_custom_widget_manager()\n",
    "    # Install pySSV for this session\n",
    "    %pip install pySSV\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb39abbe-1869-4509-8bb4-bbf44762b5b5",
   "metadata": {},
   "source": [
    "### Video\n",
    "This example takes advantage of the point cloud shader template to render video in real time. In this case, the video is compressed into a quadtree (this is obviously not a very good compression algorithm for video, but it's easy to encode/decode so it makes for a good demonstration) which is stored in a texture. Each row of the animation texture stores the quadtree for one frame where each pixel is one cell in the quadtree. The way this is implemented means the cells don't strictly need to be part of a quad tree, they just each represent a single square of a given size, colour, and location. \n",
    "\n",
    "The video quadtree is created by a separate program the code for which can be found here: https://github.com/space928/badapple-quadtree-encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273fb055-3a5a-4d51-86fc-9b41a61523b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "\n",
    "# Download the compressed video file from the internet if needed (with the user's permission)\n",
    "filename = \"badapple_quad.pkl\"\n",
    "if not os.path.isfile(filename):\n",
    "    if input(\"Encoded video file not found! Do you want to download it now (yes/no)?\")[0] == \"y\":\n",
    "        url = \"https://github.com/space928/badapple-quadtree-encoder/releases/download/0.1.0/badapple_quad.pkl\"\n",
    "        import urllib.request\n",
    "        try:\n",
    "            print(\"Downloading...\")\n",
    "            urllib.request.urlretrieve(url, filename)\n",
    "            print(\"Successfully downloaded encoded video file!\")\n",
    "        except Error as e:\n",
    "            print(f\"Failed to download video: {e}\")\n",
    "else:\n",
    "    print(f\"Video file '{filename}' already exists, using existing version...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfeeee4-d0cd-4bca-99c6-1936b7b33136",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pySSV as ssv\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "\n",
    "canvas5 = ssv.canvas(use_renderdoc=True)\n",
    "with open(\"badapple_quad.pkl\", \"rb\") as f:\n",
    "    anim, frame_lengths = pkl.load(f)\n",
    "    print(f\"Loaded animation! Animation has shape:{anim.shape}\")\n",
    "    \n",
    "canvas5.main_render_buffer.full_screen_vertex_buffer.update_vertex_buffer(np.zeros((anim.shape[0]*6), dtype=np.float32))\n",
    "\n",
    "anim = np.swapaxes(anim, 0, 1)\n",
    "# Dcelare textures, make sure that these textures as treated as ints instead of floats\n",
    "anim_tex = canvas5.texture(anim, \"uAnimTex\", treat_as_normalized_integer=False)\n",
    "frame_lengths_tex = canvas5.texture(frame_lengths, \"uFrameLengthsTex\", treat_as_normalized_integer=False)\n",
    "# Setup texture samplers\n",
    "anim_tex.repeat_x, anim_tex.repeat_y = False, False\n",
    "anim_tex.linear_filtering = False\n",
    "frame_lengths_tex.repeat_x, frame_lengths_tex.repeat_y = False, False\n",
    "frame_lengths_tex.linear_filtering = False\n",
    "\n",
    "canvas5.shader(\"\"\"\n",
    "#pragma SSV point_cloud mainPoint --non_square_points\n",
    "// These are automatically declared by the preprocessor\n",
    "//uniform isampler2D uAnimTex;\n",
    "//uniform isampler2D uFrameLengthsTex;\n",
    "VertexOutput mainPoint()\n",
    "{\n",
    "    VertexOutput o;\n",
    "    // Synchronise the playback to the time uniform, 30 FPS\n",
    "    int frame = int(uTime*30.-20.);\n",
    "    \n",
    "    int frameLen = texelFetch(uFrameLengthsTex, ivec2(0, frame), 0).r;\n",
    "    if(gl_VertexID > frameLen) \n",
    "    {\n",
    "        // Early out for verts not needed in this frame; no geometry will be generated for these as the size is set to 0\n",
    "        o.size = vec2(0.);\n",
    "        return o;\n",
    "    }\n",
    "    // This contains the data for the current quad to rendered (value (0-255), x (pixels), y (pixels), subdivision (0-n))\n",
    "    ivec4 quad = texelFetch(uAnimTex, ivec2(gl_VertexID, frame), 0);\n",
    "    // The size is determined by the subdivision level of the cell in the quad tree. \n",
    "    o.size = vec2(1./pow(2., quad.w-0.1));\n",
    "    if(quad.w == 0)\n",
    "        o.size = vec2(0.);\n",
    "    vec4 pos = vec4(float(quad.z)/480., 1.-float(quad.y)/360., 0., 1.);\n",
    "    pos.xy += o.size/vec2(2., -2.);  // Centre the point\n",
    "    pos = pos*2.-1.;  // To clip space (-1 to 1)\n",
    "    pos += vec4(in_vert, 0.)*1e-8;  // If in_vert is not used, the shader compiler optimises it out which makes OpenGL unhappy; this may be fixed in the future\n",
    "    o.position = pos;\n",
    "    o.color = vec4(vec3(float(quad.x)/255.0)+in_color, 1.0);\n",
    "    return o;\n",
    "}\n",
    "\"\"\")\n",
    "canvas5.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db72da5-cf90-4204-ba6a-738d1cab8ca0",
   "metadata": {},
   "source": [
    "### Geometry shaders\n",
    "This shader demonstrates the use of custom geometry shaders to render a vector field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625af88b-d151-4303-b0ac-0c03f82a6dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pySSV as ssv\n",
    "import numpy as np\n",
    "\n",
    "# Generate some points\n",
    "def generate_points():\n",
    "    width, depth = 64, 64\n",
    "    scale = 3\n",
    "    v_scale = 0.5\n",
    "    f = 0.01\n",
    "    verts = np.zeros((width, depth, 9), dtype='f4')\n",
    "    for z in range(depth):\n",
    "        for x in range(width):\n",
    "            dx = width/2 - x\n",
    "            dz = depth/2 - z\n",
    "            y = np.sin((dx*dx+dz*dz)*f) * v_scale\n",
    "            # Pos\n",
    "            verts[z, x, :3] = [x/width * scale, y, z/depth * scale]\n",
    "            # Colour\n",
    "            verts[z, x, 3:6] = [y/v_scale, abs(y/v_scale), np.sin(y/v_scale*10.)*0.5+0.5]\n",
    "            # Direction\n",
    "            verts[z, x, 6:9] = [dx/width, 0.1, dz/depth]\n",
    "            \n",
    "    return verts.flatten()\n",
    "\n",
    "canvas5 = ssv.canvas(use_renderdoc=True)\n",
    "# Set the contents of default vertex buffer on the main pass (normally used for full-screen shaders, but in this case hijacked for this example)\n",
    "canvas5.main_render_buffer.full_screen_vertex_buffer.update_vertex_buffer(generate_points(), (\"in_vert\", \"in_color\", \"in_dir\"))\n",
    "canvas5.main_camera.target_pos = np.array((1.5, 0, 1.5))\n",
    "#print(canvas5.dbg_preprocess_shader(\"\"\"\n",
    "canvas5.shader(\"\"\"\n",
    "#pragma SSV geometry mainPoint mainGeo --vertex_output_struct VertexOutput --geo_max_vertices 7 --custom_vertex_input\n",
    "struct VertexOutput {\n",
    "    vec4 position;\n",
    "    vec4 color;\n",
    "    vec3 dir;\n",
    "    float size;\n",
    "};\n",
    "\n",
    "#ifdef SHADER_STAGE_VERTEX\n",
    "in vec3 in_vert;\n",
    "in vec3 in_color;\n",
    "in vec3 in_dir;\n",
    "\n",
    "VertexOutput mainPoint()\n",
    "{\n",
    "    VertexOutput o;\n",
    "    vec4 pos = vec4(in_vert, 1.0);\n",
    "    //pos = uViewMat * pos;\n",
    "    //pos = uProjMat * pos;\n",
    "    o.position = pos;\n",
    "    o.color = vec4(in_color, 1.);\n",
    "    o.size = 30.0/uResolution.x;\n",
    "    o.dir = normalize(in_dir);\n",
    "    return o;\n",
    "}\n",
    "#endif\n",
    "\n",
    "#ifdef SHADER_STAGE_GEOMETRY\n",
    "void mainGeo(VertexOutput i) {\n",
    "    vec4 position = i.position;\n",
    "    float size = i.size;\n",
    "    // This output variable is defined by the template and must be written to before the first EmitVertex() call to take effect\n",
    "    out_color = i.color;\n",
    "    vec3 fwd = normalize((uViewMat * vec4(0., 0., 1., 0.)).xyz);\n",
    "    vec3 perp = normalize(cross(i.dir, fwd));\n",
    "    vec4 aspect_ratio = vec4(1., uResolution.x/uResolution.y, 1., 1.);\n",
    "    float baseWidth = 0.05;\n",
    "    float headWidth = 0.2;\n",
    "    float headLength = 0.4;\n",
    "    // Now we draw an arrow\n",
    "    // Base\n",
    "    out_color = vec4(0.,0.,0.,1.);\n",
    "    gl_Position = position + size * vec4(perp*baseWidth, 0.0) * aspect_ratio;\n",
    "    gl_Position = uProjMat * uViewMat * gl_Position;\n",
    "    EmitVertex();\n",
    "    gl_Position = position + size * vec4(-perp*baseWidth, 0.0) * aspect_ratio;\n",
    "    gl_Position = uProjMat * uViewMat * gl_Position;\n",
    "    EmitVertex();\n",
    "    out_color = i.color;\n",
    "    gl_Position = position + size * vec4(i.dir + perp*baseWidth, 0.0) * aspect_ratio;\n",
    "    gl_Position = uProjMat * uViewMat * gl_Position;\n",
    "    EmitVertex();\n",
    "    gl_Position = position + size * vec4(i.dir - perp*baseWidth, 0.0) * aspect_ratio;\n",
    "    gl_Position = uProjMat * uViewMat * gl_Position;\n",
    "    EmitVertex();\n",
    "    EndPrimitive();\n",
    "    // Head\n",
    "    gl_Position = position + size * vec4(i.dir + perp*headWidth, 0.0) * aspect_ratio;\n",
    "    gl_Position = uProjMat * uViewMat * gl_Position;\n",
    "    EmitVertex();\n",
    "    gl_Position = position + size * vec4(i.dir + -perp*headWidth, 0.0) * aspect_ratio;\n",
    "    gl_Position = uProjMat * uViewMat * gl_Position;\n",
    "    EmitVertex();\n",
    "    gl_Position = position + size * vec4(i.dir * (1.+headLength), 0.0) * aspect_ratio;\n",
    "    gl_Position = uProjMat * uViewMat * gl_Position;\n",
    "    EmitVertex();\n",
    "    EndPrimitive();\n",
    "}\n",
    "#endif\n",
    "\"\"\")#)\n",
    "canvas5.run(stream_quality=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1610dfb-7518-4721-9543-965c1073a8bb",
   "metadata": {},
   "source": [
    "### Streaming Modes\n",
    "*pySSV* supports a number of different video streaming modes to get rendered frames from the OpenGL backend into Jupyter. They each have their own advantages and disadvantages, so you can experiment with which method works best for you. `JPG` should be supported everywhere, but if your platform supports it, I would recommend `VP8` or `MJPEG`.\n",
    "\n",
    "Not all streaming modes are supported on all platforms. Google Colab is notoriously difficult to get working nicely.\n",
    "\n",
    "Here we present a particularly difficult example for video encoders, a point cloud (taken from the introduction.ipynb notebook) and how the different encoding settings affect it.\n",
    "\n",
    "The following streaming modes are supported:\n",
    "\n",
    " - JPG\n",
    " - PNG\n",
    " - VP8\n",
    " - VP9\n",
    " - H264\n",
    " - MJPEG\n",
    "\n",
    "The streaming mode is controlled using the `stream_mode` parameter of the `canvas.run()` method which accepts a `str` or an `SSVStreamingMode` (`from pySSV.ssv_render_process_server import SSVStreamingMode`). The `run()` method also takes a `stream_quality` parameter which can be used to control the compression of the encoder. It accepts a value from 0-100 (some encoders will work with values greater than 100, others clamp it) which, depending on the encoder, is scaled to give the constant bit rate or quality factor. Higher values give better quality images at the cost of higher bandwidth utilisation. When the `stream_quality` is above or equal to 90, chroma subsampling is disabled for formats that support yuv444p.\n",
    "\n",
    "#### Technical Details\n",
    "Internally, *pySSV* opens a dedicated websocket with the Jupyter frontend to stream video. On platforms where this isn't supported (notably, Google Colab) this falls back to using Jupyter Widget messages which are a bit less efficient due to the protocol's need to json encode everything. The `MJPEG` format is an exception to this as it communicates using a local HTTP server, relying on the browser's native support for `MJPEG` over HTTP; this has the advantage that `MJPEG` frames don't need to be json encoded or parsed in JS which helps a lot with latency.\n",
    "\n",
    "The image formats `JPG` and `PNG` are encoded using Pillow as base64 encoded data URLs which are passed to an `<img>`. Whereas as the video formats are encoded by libavformat (FFmpeg's encoding library) and decoded in javascript using the WebCodecs API and blitted to a canvas; hence the lack of support for Firefox for these formats. `MJPEG` is encoded by libavformat and passed directly as a URL to the local HTTP server to an `<img>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40c5792-6b2e-44ee-b217-6322d55153f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pySSV as ssv\n",
    "import numpy as np\n",
    "\n",
    "# Make the canvas size a bit bigger to put a bit more pressure on the encocers\n",
    "CANVAS_SIZE = (1280, 720)\n",
    "\n",
    "# Generate some points\n",
    "def generate_points():\n",
    "    width, depth = 64, 64\n",
    "    scale = 3\n",
    "    v_scale = 0.5\n",
    "    f = 0.01\n",
    "    verts = np.zeros((width, depth, 6), dtype='f4')\n",
    "    for z in range(depth):\n",
    "        for x in range(width):\n",
    "            dx = width/2 - x\n",
    "            dz = depth/2 - z\n",
    "            y = np.sin((dx*dx+dz*dz)*f) * v_scale\n",
    "            verts[z, x, :3] = [x/width * scale, y, z/depth * scale]\n",
    "            verts[z, x, 3:6] = [y/v_scale, abs(y/v_scale), np.sin(y/v_scale*10.)*0.5+0.5]\n",
    "            \n",
    "    return verts.flatten()\n",
    "\n",
    "def make_canvas():\n",
    "    canvas = ssv.canvas(use_renderdoc=True, size=CANVAS_SIZE)\n",
    "    # Set the contents of default vertex buffer on the main pass (normally used for full-screen shaders, but in this case hijacked for this example)\n",
    "    canvas.main_render_buffer.full_screen_vertex_buffer.update_vertex_buffer(generate_points())\n",
    "    canvas.main_camera.target_pos = np.array((1.5, 0, 1.5))\n",
    "    canvas.shader(\"\"\"\n",
    "    #pragma SSV point_cloud mainPoint\n",
    "    VertexOutput mainPoint()\n",
    "    {\n",
    "        VertexOutput o;\n",
    "        vec4 pos = vec4(in_vert, 1.0);\n",
    "        pos = uViewMat * pos;\n",
    "        pos = uProjMat * pos;\n",
    "        o.position = pos;\n",
    "        o.color = vec4(in_color, 1.);\n",
    "        o.size = 30.0/uResolution.x;\n",
    "        float d = length(uMouse/uResolution.xy*2.-1.-pos.xy/pos.z);\n",
    "        o.size += clamp(pow(smoothstep(.5, 0., d), 3.)*0.03, 0., 0.3);\n",
    "        o.color += step(d, o.size);\n",
    "        return o;\n",
    "    }\n",
    "    \"\"\")\n",
    "    return canvas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fc0389-f70c-41a5-ba7d-02e55a0522ed",
   "metadata": {},
   "source": [
    "The default settings when `canvas.run()` is called are `stream_mode=\"jpg\"` and `stream_quality=75`. When `stream_quality` is unset it defaults to the encoder's default quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c35a5e8-a2d3-4c83-9d41-07b0bdcfa5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_canvas().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca51c8a-f6d6-4384-aef4-8b342c8daeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For JPG streams, setting the stream quality to 100 can actually *improve* encoding performance (if not limited by bandwidth) as some of the optimisations can be skipped.\n",
    "make_canvas().run(stream_quality=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278c4053-fcfb-441a-98d8-5e7a4e44629d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For PNG is always lossless so the stream quality can't be controlled.\n",
    "# This format is currently the only one which supports transparency in the output.\n",
    "# It's also VERY slow to encode.\n",
    "\n",
    "# With streaming formats the produce very large frames, such as png, Jupyter/the web browser can \n",
    "# get backed up with frames, in this case the frame rate may still be reasonable, but extremely \n",
    "# high latency (and memory usage!) will be apparent. In this case you need to switch to a streaming \n",
    "# format that offers more compression or decrease the streaming quality.\n",
    "\n",
    "make_canvas().run(stream_mode=\"png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6c99b4-1825-421a-bfe2-69f414a59728",
   "metadata": {},
   "source": [
    "#### Video Formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b72dd9-1b6c-49df-8886-58fe11ba9dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VP8 offers a good balance between quality and encoding time while offering very good compression\n",
    "# Latency is also generally fairly low\n",
    "make_canvas().run(stream_mode=\"vp8\", stream_quality=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda275ec-69ac-4007-9ec1-7b3481113ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VP9 has improved compression efficiency but is much slower at encoding\n",
    "make_canvas().run(stream_mode=\"vp9\", stream_quality=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ce867f-dcd8-4308-9281-ccec97494fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# H264 is fast to encode, but the compressions isn't quite as efficient as VP8\n",
    "make_canvas().run(stream_mode=\"h264\", stream_quality=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f13d35b-c156-413e-ba20-e1e58911ec68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MJPEG has very low latency and fast encoding/decooding time, but worse compression efficiency than other video formats.\n",
    "make_canvas().run(stream_mode=\"mjpeg\", stream_quality=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b639a967-8d59-40a3-8e3e-fde8a278794d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
