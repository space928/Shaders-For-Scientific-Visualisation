{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3493ef7e-eed2-410b-b3a2-64f3a165f0b1",
   "metadata": {},
   "source": [
    "# Additional Examples\n",
    "This notebook contains more advanced examples using pySSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53a5b8c-76f5-4f15-892b-87c4ed1fa4cd",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# Google colab support\n",
    "try:\n",
    "    # Try enabling custom widgets, this will fail silently if we're not in Google Colab\n",
    "    from google.colab import output\n",
    "    output.enable_custom_widget_manager()\n",
    "    # Install pySSV for this session\n",
    "    %pip install pySSV\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb39abbe-1869-4509-8bb4-bbf44762b5b5",
   "metadata": {},
   "source": [
    "### Video\n",
    "This example takes advantage of the point cloud shader template to render video in real time. In this case, the video is compressed into a quadtree (this is obviously not a very good compression algorithm for video, but it's easy to encode/decode so it makes for a good demonstration) which is stored in a texture. Each row of the animation texture stores the quadtree for one frame where each pixel is one cell in the quadtree. The way this is implemented means the cells don't strictly need to be part of a quad tree, they just each represent a single square of a given size, colour, and location. \n",
    "\n",
    "The video quadtree is created by a separate program the code for which can be found here: https://github.com/space928/badapple-quadtree-encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273fb055-3a5a-4d51-86fc-9b41a61523b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "\n",
    "# Download the compressed video file from the internet if needed (with the user's permission)\n",
    "filename = \"badapple_quad.pkl\"\n",
    "if not os.path.isfile(filename):\n",
    "    if input(\"Encoded video file not found! Do you want to download it now (yes/no)?\")[0] == \"y\":\n",
    "        url = \"https://github.com/space928/badapple-quadtree-encoder/releases/download/0.1.0/badapple_quad.pkl\"\n",
    "        import urllib.request\n",
    "        try:\n",
    "            print(\"Downloading...\")\n",
    "            urllib.request.urlretrieve(url, filename)\n",
    "            print(\"Successfully downloaded encoded video file!\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to download video: {e}\")\n",
    "else:\n",
    "    print(f\"Video file '{filename}' already exists, using existing version...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfeeee4-d0cd-4bca-99c6-1936b7b33136",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pySSV as ssv\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "\n",
    "canvas5 = ssv.canvas(use_renderdoc=True)\n",
    "with open(\"badapple_quad.pkl\", \"rb\") as f:\n",
    "    anim, frame_lengths = pkl.load(f)\n",
    "    print(f\"Loaded animation! Animation has shape:{anim.shape}\")\n",
    "    \n",
    "canvas5.main_render_buffer.full_screen_vertex_buffer.update_vertex_buffer(np.zeros((anim.shape[0]*6), dtype=np.float32))\n",
    "\n",
    "anim = np.swapaxes(anim, 0, 1)\n",
    "# Dcelare textures, make sure that these textures as treated as ints instead of floats\n",
    "anim_tex = canvas5.texture(anim, \"uAnimTex\", treat_as_normalized_integer=False)\n",
    "frame_lengths_tex = canvas5.texture(frame_lengths, \"uFrameLengthsTex\", treat_as_normalized_integer=False)\n",
    "# Setup texture samplers\n",
    "anim_tex.repeat_x, anim_tex.repeat_y = False, False\n",
    "anim_tex.linear_filtering = False\n",
    "frame_lengths_tex.repeat_x, frame_lengths_tex.repeat_y = False, False\n",
    "frame_lengths_tex.linear_filtering = False\n",
    "\n",
    "canvas5.shader(\"\"\"\n",
    "#pragma SSV point_cloud mainPoint --non_square_points\n",
    "// These are automatically declared by the preprocessor\n",
    "//uniform isampler2D uAnimTex;\n",
    "//uniform isampler2D uFrameLengthsTex;\n",
    "VertexOutput mainPoint()\n",
    "{\n",
    "    VertexOutput o;\n",
    "    // Synchronise the playback to the time uniform, 30 FPS\n",
    "    int frame = int(uTime*30.-20.);\n",
    "    \n",
    "    int frameLen = texelFetch(uFrameLengthsTex, ivec2(0, frame), 0).r;\n",
    "    if(gl_VertexID > frameLen) \n",
    "    {\n",
    "        // Early out for verts not needed in this frame; no geometry will be generated for these as the size is set to 0\n",
    "        o.size = vec2(0.);\n",
    "        return o;\n",
    "    }\n",
    "    // This contains the data for the current quad to rendered (value (0-255), x (pixels), y (pixels), subdivision (0-n))\n",
    "    ivec4 quad = texelFetch(uAnimTex, ivec2(gl_VertexID, frame), 0);\n",
    "    // The size is determined by the subdivision level of the cell in the quad tree. \n",
    "    o.size = vec2(1./pow(2., quad.w-0.1));\n",
    "    if(quad.w == 0)\n",
    "        o.size = vec2(0.);\n",
    "    vec4 pos = vec4(float(quad.z)/480., 1.-float(quad.y)/360., 0., 1.);\n",
    "    pos.xy += o.size/vec2(2., -2.);  // Centre the point\n",
    "    pos = pos*2.-1.;  // To clip space (-1 to 1)\n",
    "    pos += vec4(in_vert, 0.)*1e-8;  // If in_vert is not used, the shader compiler optimises it out which makes OpenGL unhappy; this may be fixed in the future\n",
    "    o.position = pos;\n",
    "    o.color = vec4(vec3(float(quad.x)/255.0)+in_color, 1.0);\n",
    "    return o;\n",
    "}\n",
    "\"\"\")\n",
    "canvas5.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db72da5-cf90-4204-ba6a-738d1cab8ca0",
   "metadata": {},
   "source": [
    "### Geometry shaders\n",
    "This shader demonstrates the use of custom geometry shaders to render a vector field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625af88b-d151-4303-b0ac-0c03f82a6dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pySSV as ssv\n",
    "import numpy as np\n",
    "\n",
    "# Generate some points\n",
    "def generate_points():\n",
    "    width, depth = 64, 64\n",
    "    scale = 3\n",
    "    v_scale = 0.5\n",
    "    f = 0.01\n",
    "    verts = np.zeros((width, depth, 9), dtype='f4')\n",
    "    for z in range(depth):\n",
    "        for x in range(width):\n",
    "            dx = width/2 - x\n",
    "            dz = depth/2 - z\n",
    "            y = np.sin((dx*dx+dz*dz)*f) * v_scale\n",
    "            # Pos\n",
    "            verts[z, x, :3] = [x/width * scale, y, z/depth * scale]\n",
    "            # Colour\n",
    "            verts[z, x, 3:6] = [y/v_scale, abs(y/v_scale), np.sin(y/v_scale*10.)*0.5+0.5]\n",
    "            # Direction\n",
    "            verts[z, x, 6:9] = [dx/width, 0.1, dz/depth]\n",
    "            \n",
    "    return verts.flatten()\n",
    "\n",
    "canvas5 = ssv.canvas(use_renderdoc=True)\n",
    "# Set the contents of default vertex buffer on the main pass (normally used for full-screen shaders, but in this case hijacked for this example)\n",
    "canvas5.main_render_buffer.full_screen_vertex_buffer.update_vertex_buffer(generate_points(), (\"in_vert\", \"in_color\", \"in_dir\"))\n",
    "canvas5.main_camera.target_pos = np.array((1.5, 0, 1.5))\n",
    "#print(canvas5.dbg_preprocess_shader(\"\"\"\n",
    "canvas5.shader(\"\"\"\n",
    "#pragma SSV geometry mainPoint mainGeo --vertex_output_struct VertexOutput --geo_max_vertices 7 --custom_vertex_input\n",
    "struct VertexOutput {\n",
    "    vec4 position;\n",
    "    vec4 color;\n",
    "    vec3 dir;\n",
    "    float size;\n",
    "};\n",
    "\n",
    "#ifdef SHADER_STAGE_VERTEX\n",
    "in vec3 in_vert;\n",
    "in vec3 in_color;\n",
    "in vec3 in_dir;\n",
    "\n",
    "VertexOutput mainPoint()\n",
    "{\n",
    "    VertexOutput o;\n",
    "    vec4 pos = vec4(in_vert, 1.0);\n",
    "    //pos = uViewMat * pos;\n",
    "    //pos = uProjMat * pos;\n",
    "    o.position = pos;\n",
    "    o.color = vec4(in_color, 1.);\n",
    "    o.size = 30.0/uResolution.x;\n",
    "    o.dir = normalize(in_dir);\n",
    "    return o;\n",
    "}\n",
    "#endif\n",
    "\n",
    "#ifdef SHADER_STAGE_GEOMETRY\n",
    "void mainGeo(VertexOutput i) {\n",
    "    vec4 position = i.position;\n",
    "    float size = i.size;\n",
    "    // This output variable is defined by the template and must be written to before the first EmitVertex() call to take effect\n",
    "    out_color = i.color;\n",
    "    vec3 fwd = normalize((uViewMat * vec4(0., 0., 1., 0.)).xyz);\n",
    "    vec3 perp = normalize(cross(i.dir, fwd));\n",
    "    vec4 aspect_ratio = vec4(1., uResolution.x/uResolution.y, 1., 1.);\n",
    "    float baseWidth = 0.05;\n",
    "    float headWidth = 0.2;\n",
    "    float headLength = 0.4;\n",
    "    // Now we draw an arrow\n",
    "    // Base\n",
    "    out_color = vec4(0.,0.,0.,1.);\n",
    "    gl_Position = position + size * vec4(perp*baseWidth, 0.0) * aspect_ratio;\n",
    "    gl_Position = uProjMat * uViewMat * gl_Position;\n",
    "    EmitVertex();\n",
    "    gl_Position = position + size * vec4(-perp*baseWidth, 0.0) * aspect_ratio;\n",
    "    gl_Position = uProjMat * uViewMat * gl_Position;\n",
    "    EmitVertex();\n",
    "    out_color = i.color;\n",
    "    gl_Position = position + size * vec4(i.dir + perp*baseWidth, 0.0) * aspect_ratio;\n",
    "    gl_Position = uProjMat * uViewMat * gl_Position;\n",
    "    EmitVertex();\n",
    "    gl_Position = position + size * vec4(i.dir - perp*baseWidth, 0.0) * aspect_ratio;\n",
    "    gl_Position = uProjMat * uViewMat * gl_Position;\n",
    "    EmitVertex();\n",
    "    EndPrimitive();\n",
    "    // Head\n",
    "    gl_Position = position + size * vec4(i.dir + perp*headWidth, 0.0) * aspect_ratio;\n",
    "    gl_Position = uProjMat * uViewMat * gl_Position;\n",
    "    EmitVertex();\n",
    "    gl_Position = position + size * vec4(i.dir + -perp*headWidth, 0.0) * aspect_ratio;\n",
    "    gl_Position = uProjMat * uViewMat * gl_Position;\n",
    "    EmitVertex();\n",
    "    gl_Position = position + size * vec4(i.dir * (1.+headLength), 0.0) * aspect_ratio;\n",
    "    gl_Position = uProjMat * uViewMat * gl_Position;\n",
    "    EmitVertex();\n",
    "    EndPrimitive();\n",
    "}\n",
    "#endif\n",
    "\"\"\")#)\n",
    "canvas5.run(stream_quality=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1610dfb-7518-4721-9543-965c1073a8bb",
   "metadata": {},
   "source": [
    "### Streaming Modes\n",
    "*pySSV* supports a number of different video streaming modes to get rendered frames from the OpenGL backend into Jupyter. They each have their own advantages and disadvantages, so you can experiment with which method works best for you. `JPG` should be supported everywhere, but if your platform supports it, I would recommend `VP8` or `MJPEG`.\n",
    "\n",
    "Not all streaming modes are supported on all platforms. Google Colab is notoriously difficult to get working nicely.\n",
    "\n",
    "Here we present a particularly difficult example for video encoders, a point cloud (taken from the introduction.ipynb notebook) and how the different encoding settings affect it.\n",
    "\n",
    "The following streaming modes are supported:\n",
    "\n",
    " - JPG\n",
    " - PNG\n",
    " - VP8\n",
    " - VP9\n",
    " - H264\n",
    " - MJPEG\n",
    "\n",
    "The streaming mode is controlled using the `stream_mode` parameter of the `canvas.run()` method which accepts a `str` or an `SSVStreamingMode` (`from pySSV.ssv_render_process_server import SSVStreamingMode`). The `run()` method also takes a `stream_quality` parameter which can be used to control the compression of the encoder. It accepts a value from 0-100 (some encoders will work with values greater than 100, others clamp it) which, depending on the encoder, is scaled to give the constant bit rate or quality factor. Higher values give better quality images at the cost of higher bandwidth utilisation. When the `stream_quality` is above or equal to 90, chroma subsampling is disabled for formats that support yuv444p.\n",
    "\n",
    "#### Technical Details\n",
    "Internally, *pySSV* opens a dedicated websocket with the Jupyter frontend to stream video. On platforms where this isn't supported (notably, Google Colab) this falls back to using Jupyter Widget messages which are a bit less efficient due to the protocol's need to json encode everything. The `MJPEG` format is an exception to this as it communicates using a local HTTP server, relying on the browser's native support for `MJPEG` over HTTP; this has the advantage that `MJPEG` frames don't need to be json encoded or parsed in JS which helps a lot with latency.\n",
    "\n",
    "The image formats `JPG` and `PNG` are encoded using Pillow as base64 encoded data URLs which are passed to an `<img>`. Whereas as the video formats are encoded by libavformat (FFmpeg's encoding library) and decoded in javascript using the WebCodecs API and blitted to a canvas; hence the lack of support for Firefox for these formats. `MJPEG` is encoded by libavformat and passed directly as a URL to the local HTTP server to an `<img>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40c5792-6b2e-44ee-b217-6322d55153f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pySSV as ssv\n",
    "import numpy as np\n",
    "\n",
    "# Make the canvas size a bit bigger to put a bit more pressure on the encocers\n",
    "CANVAS_SIZE = (1280, 720)\n",
    "\n",
    "# Generate some points\n",
    "def generate_points():\n",
    "    width, depth = 64, 64\n",
    "    scale = 3\n",
    "    v_scale = 0.5\n",
    "    f = 0.01\n",
    "    verts = np.zeros((width, depth, 6), dtype='f4')\n",
    "    for z in range(depth):\n",
    "        for x in range(width):\n",
    "            dx = width/2 - x\n",
    "            dz = depth/2 - z\n",
    "            y = np.sin((dx*dx+dz*dz)*f) * v_scale\n",
    "            verts[z, x, :3] = [x/width * scale, y, z/depth * scale]\n",
    "            verts[z, x, 3:6] = [y/v_scale, abs(y/v_scale), np.sin(y/v_scale*10.)*0.5+0.5]\n",
    "            \n",
    "    return verts.flatten()\n",
    "\n",
    "def make_canvas():\n",
    "    canvas = ssv.canvas(use_renderdoc=True, size=CANVAS_SIZE)\n",
    "    # Set the contents of default vertex buffer on the main pass (normally used for full-screen shaders, but in this case hijacked for this example)\n",
    "    canvas.main_render_buffer.full_screen_vertex_buffer.update_vertex_buffer(generate_points())\n",
    "    canvas.main_camera.target_pos = np.array((1.5, 0, 1.5))\n",
    "    canvas.shader(\"\"\"\n",
    "    #pragma SSV point_cloud mainPoint\n",
    "    VertexOutput mainPoint()\n",
    "    {\n",
    "        VertexOutput o;\n",
    "        vec4 pos = vec4(in_vert, 1.0);\n",
    "        pos = uViewMat * pos;\n",
    "        pos = uProjMat * pos;\n",
    "        o.position = pos;\n",
    "        o.color = vec4(in_color, 1.);\n",
    "        o.size = 30.0/uResolution.x;\n",
    "        float d = length(uMouse/uResolution.xy*2.-1.-pos.xy/pos.z);\n",
    "        o.size += clamp(pow(smoothstep(.5, 0., d), 3.)*0.03, 0., 0.3);\n",
    "        o.color += step(d, o.size);\n",
    "        return o;\n",
    "    }\n",
    "    \"\"\")\n",
    "    return canvas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fc0389-f70c-41a5-ba7d-02e55a0522ed",
   "metadata": {},
   "source": [
    "The default settings when `canvas.run()` is called are `stream_mode=\"jpg\"` and `stream_quality=75`. When `stream_quality` is unset it defaults to the encoder's default quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c35a5e8-a2d3-4c83-9d41-07b0bdcfa5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_canvas().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca51c8a-f6d6-4384-aef4-8b342c8daeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For JPG streams, setting the stream quality to 100 can actually *improve* encoding performance (if not limited by bandwidth) as some of the optimisations can be skipped.\n",
    "make_canvas().run(stream_quality=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278c4053-fcfb-441a-98d8-5e7a4e44629d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For PNG is always lossless so the stream quality can't be controlled.\n",
    "# This format is currently the only one which supports transparency in the output.\n",
    "# It's also VERY slow to encode.\n",
    "\n",
    "# With streaming formats the produce very large frames, such as png, Jupyter/the web browser can \n",
    "# get backed up with frames, in this case the frame rate may still be reasonable, but extremely \n",
    "# high latency (and memory usage!) will be apparent. In this case you need to switch to a streaming \n",
    "# format that offers more compression or decrease the streaming quality.\n",
    "\n",
    "make_canvas().run(stream_mode=\"png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6c99b4-1825-421a-bfe2-69f414a59728",
   "metadata": {},
   "source": [
    "#### Video Formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b72dd9-1b6c-49df-8886-58fe11ba9dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VP8 offers a good balance between quality and encoding time while offering very good compression\n",
    "# Latency is also generally fairly low\n",
    "make_canvas().run(stream_mode=\"vp8\", stream_quality=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda275ec-69ac-4007-9ec1-7b3481113ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VP9 has improved compression efficiency but is much slower at encoding\n",
    "make_canvas().run(stream_mode=\"vp9\", stream_quality=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ce867f-dcd8-4308-9281-ccec97494fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# H264 is fast to encode, but the compressions isn't quite as efficient as VP8\n",
    "make_canvas().run(stream_mode=\"h264\", stream_quality=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f13d35b-c156-413e-ba20-e1e58911ec68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MJPEG has very low latency and fast encoding/decooding time, but worse compression efficiency than other video formats.\n",
    "make_canvas().run(stream_mode=\"mjpeg\", stream_quality=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70a023d-9a18-46b3-9b6c-76e63c19ac2a",
   "metadata": {},
   "source": [
    "### Heightmap Demo\n",
    "This example downloads DEM (digital elevation model) data from an online API and renders it in 3d using a shader.\n",
    "\n",
    "The DEM data in question is derived from the SRTM1 (https://www2.jpl.nasa.gov/srtm/) dataset which covers most of the world (from 56°S to 60°N) at a resolution of 1 arc second (roughly 30m at the equator). Voids, trees, and buildings in the dataset have been removed.\n",
    "\n",
    "The API returns a single tile which covers 1 degree by 1 degree. Special thanks to Adam Mathieson (https://github.com/amathieson) for hosting and maintaining this API, it is only to be used for the purpose of this demo.\n",
    "\n",
    "The colouring of the data is purely for aesthetic interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c139a3-661c-4279-914f-145d821df56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a point of interest\n",
    "lat, lon = 46.2059915, 6.1475919  # Geneva, Switzerland\n",
    "poi_name = \"Geneva\"\n",
    "\n",
    "# Glasgow doesn't work very well...\n",
    "# lat, lon = 55.8579612,-4.2582393  # Glasgow, Scotland\n",
    "# poi_name = \"Glasgow Central Station\"\n",
    "\n",
    "lat, lon = 35.36283,138.7312618  # Mount Fuji, Japan\n",
    "poi_name = \"Mount Fuji\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488b49c2-728b-475e-ae11-03dd0784cefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import zlib\n",
    "from PIL import Image\n",
    "import os.path\n",
    "import numpy as np\n",
    "import pySSV as ssv\n",
    "\n",
    "# Download the needed DEM tiles\n",
    "# This snippet is derived from code written by Adam Mathieson, reused with permission\n",
    "api_url = \"https://cdn.whats-that-mountain.site/\"\n",
    "def latlon2ne(lat, lon):\n",
    "    return f\"{'s' if lat<0 else 'n'}{abs(math.floor(lat)):02d}{'w' if lon<0 else 'e'}{abs(math.floor(lon)):03d}\"\n",
    "\n",
    "def get_tile(lat, lon):\n",
    "    tile_name = f\"{latlon2ne(lat, lon)}.hgt.gz\"\n",
    "    if not os.path.isfile(tile_name):\n",
    "        import urllib.request\n",
    "        try:\n",
    "            print(f\"Downloading {api_url + tile_name}...\")\n",
    "            opener = urllib.request.URLopener()\n",
    "            opener.addheader('User-Agent', 'python-ssv-demo')\n",
    "            opener.retrieve(api_url + tile_name, tile_name)\n",
    "            print(\"Done!\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to heightmap tile: {e}\")\n",
    "    return tile_name\n",
    "\n",
    "corners = [\n",
    "    (lat+.5, lon-.5),  # top left\n",
    "    (lat+.5, lon+.5),  # top right\n",
    "    (lat-.5, lon-.5),  # bottom left\n",
    "    (lat-.5, lon+.5),  # bottom right\n",
    "]\n",
    "\n",
    "# Open and decompress the tile\n",
    "tile_name = get_tile(lat, lon)\n",
    "with open(tile_name, \"rb\") as f:\n",
    "    data = zlib.decompress(f.read())\n",
    "    tile = np.array(np.frombuffer(data, np.int16))\n",
    "    tile = tile.byteswap(inplace=True)\n",
    "    tile = tile.reshape((3601, 3601))\n",
    "    # print(tile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e655607-083f-478f-a148-f1490b3c2e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new canvas and shader to render the tile\n",
    "canvas = ssv.canvas(use_renderdoc=True)\n",
    "tex = canvas.texture(tile, \"uHeightMap\", force_2d=True)\n",
    "tex.repeat_x, tex.repeat_y = True, True\n",
    "tex.linear_filtering = True\n",
    "\n",
    "# In this example we use a simple SDF to view the heightmap in 3D\n",
    "canvas.shader(\"\"\"\n",
    "#pragma SSV sdf sdf_main --render_mode SOLID --camera_mode INTERACTIVE\n",
    "\n",
    "float sdf_main(vec3 p) {\n",
    "    // Sample the heightfield and scale it as desired\n",
    "    float disp = texture(uHeightMap, fract(p.xz*0.1+.5)).r*5.+.3;\n",
    "    // Return the signed distance to the surface. Note that this is not an exact SDF and fails anywhere where \n",
    "    // the steepness exceeds 67.5deg. The final *.5, scales the distance field such that steeper angles can \n",
    "    // be used (67.5deg instead of 45deg) at the cost of more marching steps be required.\n",
    "    return (p.y-disp)*.5;\n",
    "}\n",
    "\"\"\")\n",
    "canvas.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742ddfa6-4455-48fd-b5c9-ff70304b2f41",
   "metadata": {},
   "source": [
    "Now we try rendering the heightfield as a mesh:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa77a97-6333-4106-9f22-8c4afc1e9e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the mesh vertices\n",
    "res = 3601\n",
    "res = res//4  # Reduce vertex count for performance\n",
    "\n",
    "# Make a grid of x, y, r, g, b\n",
    "lin = np.linspace(0, 1, res)\n",
    "zeros = np.zeros((res, res))\n",
    "x,y = np.meshgrid(lin, lin)\n",
    "verts = np.dstack((x,y,zeros, zeros,zeros))\n",
    "# print(verts.shape)\n",
    "\n",
    "# Define the triangles for the grid\n",
    "inds = np.arange(0, res*(res-1))  # Create an array of indexes (skipping the last row of vertices)\n",
    "inds = inds[(inds+1)%res!=0]  # Now skip the last column of vertices\n",
    "inds = np.dstack((inds, inds+1, inds+res, inds+1, inds+res+1, inds+res))  # Now create the indices for a quad for each point. A quad is defined by the indices (n, n+1, n+w, n+1, n+w+1, n+w)\n",
    "# print(inds)\n",
    "\n",
    "inds = np.array(inds.flatten(), dtype=np.int32)\n",
    "verts = np.array(verts.flatten(), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7f8f09-ab27-4fd2-a13a-aa9f01f25445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new canvas and shader to render the tile\n",
    "canvas = ssv.canvas((1280, 720), use_renderdoc=True)\n",
    "\n",
    "# Bind the texture\n",
    "tex = canvas.texture(tile, \"uHeightMap\", force_2d=True)\n",
    "tex.repeat_x, tex.repeat_y = False, False\n",
    "tex.linear_filtering = True\n",
    "\n",
    "# Update the vertex buffer with a grid of vertices\n",
    "vb = canvas.main_render_buffer.vertex_buffer()\n",
    "vb.update_vertex_buffer(verts, index_array=inds)\n",
    "\n",
    "# Create a GUI to interact with the example, see the gui_examples notebook for more info on using GUIs\n",
    "from pySSV.ssv_gui import create_gui, SSVGUI\n",
    "from pySSV import ssv_colour\n",
    "class MyGUI:\n",
    "    slider_vertical_scale = 2.2\n",
    "    slider_sun_p = 50.\n",
    "    slider_sun_h = 180.\n",
    "    slider_snow = 40.\n",
    "    slider_dbg = 1.\n",
    "    \n",
    "    def on_gui_draw(self, gui: SSVGUI):\n",
    "        gui.begin_vertical(pad=True)\n",
    "        gui.rounded_rect(ssv_colour.ui_base_bg, overlay_last=True)\n",
    "        gui.button(\"pySSV DEM Terrain Demo\", ssv_colour.orange)\n",
    "        self.slider_vertical_scale = gui.slider(f\"Vertical scale: {float(self.slider_vertical_scale):.3f}\", \n",
    "                                                self.slider_vertical_scale, min_value=0, max_value=50, power=3.)\n",
    "        self.slider_sun_p = gui.slider(f\"Sun pitch: {float(self.slider_sun_p):.3f}\", \n",
    "                                       self.slider_sun_p, min_value=0, max_value=90)\n",
    "        self.slider_sun_h = gui.slider(f\"Sun heading: {float(self.slider_sun_h):.3f}\", \n",
    "                                       self.slider_sun_h, min_value=0, max_value=360)\n",
    "        self.slider_snow = gui.slider(f\"Snow height: {float(self.slider_snow):.3f}\", \n",
    "                                      self.slider_snow, min_value=0, max_value=100, power=3.)\n",
    "        self.slider_dbg = gui.slider(f\"Debug: {float(self.slider_dbg):.3f}\", \n",
    "                                      self.slider_dbg, min_value=0, max_value=10, power=3.)\n",
    "        \n",
    "        gui.space(height=30)\n",
    "        gui.end_vertical()\n",
    "        horiz_scale = 2.\n",
    "        x, z = ((lat-math.floor(lat))*2.-1.)*horiz_scale, -((lon-math.floor(lon))*2.-1.)*horiz_scale\n",
    "        # print(z, x)\n",
    "        gui.label_3d(poi_name, (x, 0.025, z), font_size=12., shadow=True)\n",
    "\n",
    "    def on_post_gui(self, gui: SSVGUI):\n",
    "        gui.canvas.update_uniform(\"uVerticalScale\", float(self.slider_vertical_scale))\n",
    "        gui.canvas.update_uniform(\"uSunPitch\", float(self.slider_sun_p))\n",
    "        gui.canvas.update_uniform(\"uSunHeading\", float(self.slider_sun_h))\n",
    "        gui.canvas.update_uniform(\"uSnowHeight\", float(self.slider_snow))\n",
    "        gui.canvas.update_uniform(\"uDebug\", float(self.slider_dbg))\n",
    "\n",
    "gui = create_gui(canvas)\n",
    "my_gui = MyGUI()\n",
    "# Register a callback to the on_gui event\n",
    "gui.on_gui(lambda x: my_gui.on_gui_draw(x))\n",
    "gui.on_post_gui(lambda x: my_gui.on_post_gui(x))\n",
    "canvas.update_uniform(\"uVerticalScale\", my_gui.slider_vertical_scale)\n",
    "\n",
    "# Create a shader to render the sky\n",
    "canvas.shader(\"\"\"\n",
    "#pragma SSV pixel pixel\n",
    "\n",
    "uniform float uSunPitch;\n",
    "uniform float uSunHeading;\n",
    "uniform float uDebug;\n",
    "\n",
    "const mat3 xyzToSrgb = mat3 (\n",
    "\t 3.24100323297636050, -0.96922425220251640,  0.05563941985197549,\n",
    "\t-1.53739896948878640,  1.87592998369517530, -0.20401120612391013,\n",
    "\t-0.49861588199636320,  0.04155422634008475,  1.05714897718753330\n",
    ");\n",
    "\n",
    "vec3 reinhard2(vec3 x) {\n",
    "    const float L_white = 4.0;\n",
    "    return (x * (1.0 + x / (L_white * L_white))) / (1.0 + x);\n",
    "}\n",
    "\n",
    "vec4 pixel(vec2 fragCoord) {\n",
    "    vec2 uv = (fragCoord/uResolution.xy)*2.-1.;\n",
    "    vec3 eye = normalize((vec4(uv, -1., 0.) * uViewMat).xyz);\n",
    "    \n",
    "    float sp = cos(radians(uSunPitch));\n",
    "    vec3 sun = vec3(cos(radians(uSunHeading))*sp, sin(radians(uSunPitch)), sin(radians(uSunHeading))*sp);\n",
    "    float mie = pow(max(dot(eye, sun), 0.), 4.);\n",
    "\n",
    "    float p = (1.-sp)*0.5+0.25;\n",
    "    vec2 g = pow(.8-max(eye.yy, 0.)*0.5, vec2(3.0+p*0.1, 3.0));\n",
    "    vec3 col = xyzToSrgb * vec3(g.x, g.y, pow((1.-abs(eye.y)), 2.)*p+p);\n",
    "    col += vec3(0.95, 0.93, 0.9) * mie*0.5;\n",
    "    col = smoothstep(0., 1., reinhard2(col)*1.8);\n",
    "\n",
    "    return vec4(col, 1.);\n",
    "}\n",
    "\"\"\")\n",
    "\n",
    "# Create a shader to render the terrain\n",
    "vb.shader(\"\"\"\n",
    "#pragma SSV vert_pixel vert pixel\n",
    "\n",
    "uniform float uVerticalScale;\n",
    "uniform float uSunPitch;\n",
    "uniform float uSunHeading;\n",
    "uniform float uSnowHeight;\n",
    "uniform float uDebug;\n",
    "\n",
    "const float horizScale = 2.;\n",
    "const float texelSize = 1./3601.;\n",
    "\n",
    "#ifdef SHADER_STAGE_VERTEX\n",
    "layout(location = 3) out vec2 uv;\n",
    "\n",
    "void vert() {\n",
    "    uv = in_vert.xy;\n",
    "    uv = 1.-uv;\n",
    "    uv = uv.yx;\n",
    "    float disp = texture(uHeightMap, uv.xy).r;\n",
    "    vec2 v = (in_vert.xy*2.-1.)*horizScale;\n",
    "    gl_Position = vec4(v.x, disp*uVerticalScale, v.y, 1.);\n",
    "    gl_Position = uProjMat * uViewMat * gl_Position;\n",
    "}\n",
    "#endif\n",
    "\n",
    "#ifdef SHADER_STAGE_FRAGMENT\n",
    "layout(location = 3) in vec2 uv;\n",
    "\n",
    "float radians(float x) {\n",
    "    return x/180.*3.14159265;\n",
    "}\n",
    "\n",
    "vec3 reinhard2(vec3 x) {\n",
    "    const float L_white = 4.0;\n",
    "    return (x * (1.0 + x / (L_white * L_white))) / (1.0 + x);\n",
    "}\n",
    "\n",
    "// BRDF functions taken from:\n",
    "// https://www.shadertoy.com/view/XlKSDR\n",
    "float pow5(float x) {\n",
    "    float x2 = x*x;\n",
    "    return x2*x2*x;\n",
    "}\n",
    "float dGGX(float linearRoughness, float ndoth, const vec3 h) {\n",
    "    // Walter et al. 2007, \"Microfacet Models for Refraction through Rough Surfaces\"\n",
    "    float oneMinusNoHSquared = 1.0 - ndoth * ndoth;\n",
    "    float a = ndoth * linearRoughness;\n",
    "    float k = linearRoughness / (oneMinusNoHSquared + a * a);\n",
    "    float d = k * k * (1.0 / 3.141592);\n",
    "    return d;\n",
    "}\n",
    "float vSmithGGXCorrelated(float linearRoughness, float NoV, float NoL) {\n",
    "    // Heitz 2014, \"Understanding the Masking-Shadowing Function in Microfacet-Based BRDFs\"\n",
    "    float a2 = linearRoughness * linearRoughness;\n",
    "    float GGXV = NoL * sqrt((NoV - a2 * NoV) * NoV + a2);\n",
    "    float GGXL = NoV * sqrt((NoL - a2 * NoL) * NoL + a2);\n",
    "    return 0.5 / (GGXV + GGXL);\n",
    "}\n",
    "vec3 fSchlick(const vec3 f0, float VoH) {\n",
    "    // Schlick 1994, \"An Inexpensive BRDF Model for Physically-Based Rendering\"\n",
    "    return f0 + (vec3(1.0) - f0) * pow5(1.0 - VoH);\n",
    "}\n",
    "\n",
    "vec4 pixel(vec3 pos) {\n",
    "    float h = texture(uHeightMap, uv).r;\n",
    "    // Compute the normals by finite differences\n",
    "    vec3 nrm = vec3(0.);\n",
    "    nrm.z = h - texture(uHeightMap, uv - vec2(texelSize, 0.)).r;\n",
    "    nrm.x = h - texture(uHeightMap, uv - vec2(0., texelSize)).r;\n",
    "    nrm.xz *= uVerticalScale/horizScale/texelSize/2.;\n",
    "    nrm.y = 1.;//-sqrt(nrm.x*nrm.x + nrm.z*nrm.z);\n",
    "    nrm = normalize(nrm);\n",
    "\n",
    "    // Lighting\n",
    "    float sp = cos(radians(uSunPitch));\n",
    "    vec3 sun = vec3(cos(radians(uSunHeading))*sp, sin(radians(uSunPitch)), sin(radians(uSunHeading))*sp);\n",
    "    vec2 screenPos = (gl_FragCoord.xy/uResolution.xy*2.-1.) * vec2(1., uResolution.y/uResolution.x);\n",
    "    vec3 eye = normalize((vec4(screenPos, 1., 0.) * uViewMat).xyz);\n",
    "    float ndotl = dot(nrm, sun);\n",
    "    float ndotv = dot(nrm, eye);\n",
    "    vec3 half = normalize(eye + sun);\n",
    "    float ndoth = clamp(dot(nrm, half), 0., 1.);\n",
    "    vec3 sunCol = pow(vec3(1., 0.9, 0.75), vec3(sp*sp*sp*2.5+1.));\n",
    "\n",
    "    // Texturing\n",
    "    const vec3 water = vec3(0, 40./255., 49./255.)*1.2;\n",
    "    const vec3 city = vec3(101./255, 115./255., 88./255.)*1.2;\n",
    "    const vec3 forest = vec3(10./255., 42./255., 24./255.)*1.2;\n",
    "    const vec3 cliff = vec3(214./255., 220./255., 173./255.)*.5;\n",
    "    const vec3 snow = vec3(247./255., 247./255., 255./255.)*1.2;\n",
    "\n",
    "    float water_city = smoothstep(11.034/1000., 12.052/1000., h);\n",
    "    float city_forest = smoothstep(10.4/1000., 24./1000., h);\n",
    "    float forest_cliff = smoothstep(0.6, 0., abs(nrm.y));\n",
    "    float cliff_snow = smoothstep((uSnowHeight)/1000., (45.+uSnowHeight)/1000., h) * smoothstep(0.3, 0.5, abs(nrm.y));\n",
    "    vec3 alb = water;\n",
    "    alb = mix(alb, city, water_city);\n",
    "    alb = mix(alb, forest, city_forest);\n",
    "    alb = mix(alb, cliff, forest_cliff);\n",
    "    alb = mix(alb, snow, cliff_snow);\n",
    "\n",
    "    // Specular\n",
    "    float rough = clamp((alb.g*0.6+water_city*0.9)*0.7*uDebug, 0., 1.);\n",
    "    rough *= rough;\n",
    "    float specD = dGGX(rough, ndoth, half);\n",
    "    specD *= vSmithGGXCorrelated(rough, clamp(ndotv, 0., 1.), clamp(ndotl, 0., 1.));\n",
    "    vec3 spec = vec3(specD);\n",
    "    spec *= fSchlick(vec3(0.04), clamp(dot(eye, half), 0., 1.));\n",
    "\n",
    "    // Composition\n",
    "    vec3 col = alb;\n",
    "    col *= (ndotl*.5+.5) * sunCol;\n",
    "    col += clamp(spec, 0., 10.) * clamp(ndotl, 0., 1.) * sunCol;\n",
    "    col *= 2.;\n",
    "    col = smoothstep(0., 1., reinhard2(col)*1.2);\n",
    "    //col = vec3(rough);\n",
    "    \n",
    "    return vec4(col, 1.);\n",
    "}\n",
    "#endif\n",
    "\"\"\")\n",
    "canvas.run(stream_quality=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56886f3d-d1a4-49db-ab05-4159b4d2e8d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8653914b-fb1f-49a0-8412-b5caf25b8943",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
